{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7284990,"sourceType":"datasetVersion","datasetId":4224362}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-27T04:26:40.639518Z","iopub.execute_input":"2023-12-27T04:26:40.640380Z","iopub.status.idle":"2023-12-27T04:26:41.028601Z","shell.execute_reply.started":"2023-12-27T04:26:40.640346Z","shell.execute_reply":"2023-12-27T04:26:41.027603Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/mldog1/users.dat\n/kaggle/input/mldog1/ratings.dat\n/kaggle/input/mldog1/movies_train.dat\n/kaggle/input/mldog1/genres.txt\n/kaggle/input/mldog1/movies_test.dat\n","output_type":"stream"}]},{"cell_type":"code","source":"%ls","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:41.030584Z","iopub.execute_input":"2023-12-27T04:26:41.030974Z","iopub.status.idle":"2023-12-27T04:26:42.065129Z","shell.execute_reply.started":"2023-12-27T04:26:41.030946Z","shell.execute_reply":"2023-12-27T04:26:42.063758Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport cv2\nimport os\nfrom nltk import wordpunct_tokenize\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:42.066739Z","iopub.execute_input":"2023-12-27T04:26:42.067208Z","iopub.status.idle":"2023-12-27T04:26:49.187839Z","shell.execute_reply.started":"2023-12-27T04:26:42.067164Z","shell.execute_reply":"2023-12-27T04:26:49.186905Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"users = pandas.read_csv('/kaggle/input/mldog1/users.dat', sep='::',\n                        engine='python',\n                        names=['userid', 'gender', 'age', 'occupation', 'zip']).set_index('userid')\nratings = pandas.read_csv('/kaggle/input/mldog1/ratings.dat', engine='python',\n                          sep='::', names=['userid', 'movieid', 'rating', 'timestamp'])\nmovies_train = pandas.read_csv('/kaggle/input/mldog1/movies_train.dat', engine='python',\n                         sep='::', names=['movieid', 'title', 'genre'], encoding='latin-1', index_col=False)\nmovies_test = pandas.read_csv('/kaggle/input/mldog1/movies_test.dat', engine='python',\n                         sep='::', names=['movieid', 'title', 'genre'], encoding='latin-1', index_col=False)\nmovies_train['genre'] = movies_train.genre.str.split('|')\nmovies_test['genre'] = movies_test.genre.str.split('|')\n\nusers.age = users.age.astype('category')\nusers.gender = users.gender.astype('category')\nusers.occupation = users.occupation.astype('category')\nratings.movieid = ratings.movieid.astype('category')\nratings.userid = ratings.userid.astype('category')","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:49.189355Z","iopub.execute_input":"2023-12-27T04:26:49.189924Z","iopub.status.idle":"2023-12-27T04:26:57.643258Z","shell.execute_reply.started":"2023-12-27T04:26:49.189885Z","shell.execute_reply":"2023-12-27T04:26:57.642356Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"a = set()\nfor i in ratings['movieid']:\n    a.add(i)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:57.645575Z","iopub.execute_input":"2023-12-27T04:26:57.645861Z","iopub.status.idle":"2023-12-27T04:26:57.843724Z","shell.execute_reply.started":"2023-12-27T04:26:57.645835Z","shell.execute_reply":"2023-12-27T04:26:57.842869Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor i in movies_test['movieid']:\n    if i in a:\n        continue\n    else:\n        count+=1","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:57.844979Z","iopub.execute_input":"2023-12-27T04:26:57.845367Z","iopub.status.idle":"2023-12-27T04:26:57.851081Z","shell.execute_reply.started":"2023-12-27T04:26:57.845336Z","shell.execute_reply":"2023-12-27T04:26:57.850080Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(count)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:57.852378Z","iopub.execute_input":"2023-12-27T04:26:57.852763Z","iopub.status.idle":"2023-12-27T04:26:57.863603Z","shell.execute_reply.started":"2023-12-27T04:26:57.852736Z","shell.execute_reply":"2023-12-27T04:26:57.862655Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"34\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n\n# Use the intersection of sets to get common movieids\ncommon_movieids = set(movies_train['movieid']).intersection(ratings['movieid'])\narray = np.random.randint(10, size=(2, 3)) ","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:57.864814Z","iopub.execute_input":"2023-12-27T04:26:57.865226Z","iopub.status.idle":"2023-12-27T04:26:57.955355Z","shell.execute_reply.started":"2023-12-27T04:26:57.865187Z","shell.execute_reply":"2023-12-27T04:26:57.954507Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def tokenize(text):\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = text.lower()\n    tokens = wordpunct_tokenize(text)\n    tokens = tokens[:-1] # remove last token because it is the year which maybe is not useful\n    return tokens\n\ndef create_vocab():\n    df = movies_train.copy()\n    arr_title = df['title'].tolist()\n    vocab = set()\n    for title in arr_title:\n        tokens = tokenize(title)\n        vocab.update(tokens)\n    vocab = list(vocab)\n    pad_token = '<PAD>'\n    unk_token = '<UNK>'\n    vocab.append(pad_token)\n    vocab.append(unk_token)\n    return vocab","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:57.956628Z","iopub.execute_input":"2023-12-27T04:26:57.957042Z","iopub.status.idle":"2023-12-27T04:26:57.964548Z","shell.execute_reply.started":"2023-12-27T04:26:57.956994Z","shell.execute_reply":"2023-12-27T04:26:57.963598Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"movie_ids = ratings.movieid.unique()\nres = {}\nn = len(ratings.userid.unique())\ntemp = ratings['rating'].values\n\nfor movie_id in movie_ids:\n    tmp = np.zeros(n)\n    cur_users = ratings.loc[ratings['movieid']==movie_id].userid.tolist()\n    for user in cur_users:\n        tmp[user - 1] = temp[user-1]\n    res[movie_id] = tmp","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:57.965756Z","iopub.execute_input":"2023-12-27T04:26:57.966108Z","iopub.status.idle":"2023-12-27T04:27:02.411131Z","shell.execute_reply.started":"2023-12-27T04:26:57.966075Z","shell.execute_reply":"2023-12-27T04:27:02.410091Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MLDataset(Dataset):\n    def __init__(self, is_train=True):\n        if is_train:\n            self.data =  movies_train\n        else:\n            self.data = movies_test\n        self.data['title_tokens'] = [tokenize(x) for x in self.data.title]\n        self.ratings = res\n        # create vocab\n        vocab = create_vocab()\n        pad_token = '<PAD>'\n        unk_token = '<UNK>'\n        self.token2idx = {token: idx for idx, token in enumerate(vocab)}\n\n        # Create a binary vector for each word in each sentence\n        MAX_LENGTH = 7\n        vectors = []\n        for title_tokens in self.data.title_tokens.tolist():\n            if len(title_tokens) < MAX_LENGTH:\n                num_pad = MAX_LENGTH - len(title_tokens)\n                for idx in range(num_pad):\n                    title_tokens.append(pad_token)\n            else:\n                title_tokens = title_tokens[:MAX_LENGTH]\n            title_vectors = []\n            for word in title_tokens:\n                binary_vector = np.zeros(len(vocab))\n                if word in vocab:\n                    binary_vector[self.token2idx[word]] = 1\n                else:\n                    binary_vector[self.token2idx[unk_token]] = 1\n                title_vectors.append(binary_vector)\n\n            vectors.append(np.array(title_vectors))\n        self.data['vectors'] = vectors\n\n        # label genre\n        with open('/kaggle/input/mldog1/genres.txt', 'r') as f:\n            genre_all = f.readlines()\n            genre_all = [x.replace('\\n','') for x in genre_all]\n        self.genre2idx = {genre:idx for idx, genre in enumerate(genre_all)}\n\n    def __getitem__(self, index):\n        title = self.data.iloc[index].title\n#         img_path = self.data.iloc[index].img_path\n        genre = self.data.iloc[index].genre\n        movie_id = self.data.iloc[index].movieid\n        try:\n            ratings = self.ratings[movie_id]\n            ratings = ratings/5\n        except:\n            #ratings = np.random.randint(5, size=(6040)) \n            #ratings = ratings/5\n            ratings = np.zeros([6040])\n        rating_tensor = torch.from_numpy(ratings).float()\n        # preprocess text\n        title_vector = self.data.iloc[index].vectors\n        title_tensor = torch.from_numpy(title_vector).float()\n\n        # preprocess im\n\n        # preprocess label\n        genre_vector = np.zeros(len(self.genre2idx))\n\n        for g in genre:\n            genre_vector[self.genre2idx[g]] = 1\n        genre_tensor = torch.from_numpy(genre_vector).float()\n        return title_tensor, genre_tensor, rating_tensor\n\n    def __len__(self):\n        return len(self.data)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:27:02.412391Z","iopub.execute_input":"2023-12-27T04:27:02.412744Z","iopub.status.idle":"2023-12-27T04:27:02.430522Z","shell.execute_reply.started":"2023-12-27T04:27:02.412713Z","shell.execute_reply":"2023-12-27T04:27:02.429469Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class RatingModel(nn.Module):\n#     def __init__(self):\n#         super(RatingModel, self).__init__()\n#         self.lin1 = nn.Linear(6040, 1510, bias=True)\n#         self.relu = nn.ReLU(inplace=True)\n#         self.dropout = nn.Dropout(0.2)\n#         self.lin2 = nn.Linear(1510, 256 , bias=True)\n#         self.lin3 = nn.Linear(256, 18, bias=True)\n#         self.bn1 = nn.BatchNorm1d(1510)\n        \n#     def forward(self, ratings):\n#         ratings = self.relu(self.lin1(ratings))\n#         ratings = self.bn1(ratings)\n#         ratings = self.dropout(ratings)\n#         ratings = self.lin2(ratings)\n#         ratings = self.relu(ratings)\n#         ratings = self.dropout(ratings)\n#         ratings = self.lin3(ratings)\n        \n#         return ratings","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:27:02.431851Z","iopub.execute_input":"2023-12-27T04:27:02.432211Z","iopub.status.idle":"2023-12-27T04:27:02.449801Z","shell.execute_reply.started":"2023-12-27T04:27:02.432183Z","shell.execute_reply":"2023-12-27T04:27:02.449006Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class RatingModel(nn.Module):\n    def __init__(self, num_classes):\n        super(RatingModel, self).__init__()\n        self.dropout = nn.Dropout(0.2)\n\n        self.fc1 = nn.Linear(6040, 1024)\n        self.bn1 = nn.BatchNorm1d(1024)\n        self.relu1 = nn.ReLU()\n\n        self.fc2 = nn.Linear(1024, 512)\n        self.bn2 = nn.BatchNorm1d(512)\n        self.relu2 = nn.ReLU()\n\n        self.fc3 = nn.Linear(512, 256)\n        self.bn3 = nn.BatchNorm1d(256)\n        self.relu3 = nn.ReLU()\n\n        self.fc4 = nn.Linear(256, num_classes)\n        \n        \n    def forward(self, x):\n        x = self.bn1(self.relu1(self.fc1(x)))\n        x = self.dropout(x)\n        x = self.bn2(self.relu2(self.fc2(x)))\n        x = self.dropout(x)\n        x = self.relu3(self.fc3(x))\n\n        x = self.fc4(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:27:02.451055Z","iopub.execute_input":"2023-12-27T04:27:02.451429Z","iopub.status.idle":"2023-12-27T04:27:02.468470Z","shell.execute_reply.started":"2023-12-27T04:27:02.451392Z","shell.execute_reply":"2023-12-27T04:27:02.467658Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_set = MLDataset(is_train=True)\ntest_set = MLDataset(is_train=False)\n\nBATCH_SIZE = 8\ntrain_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE,drop_last=True)\ntest_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE,drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:27:02.472239Z","iopub.execute_input":"2023-12-27T04:27:02.472736Z","iopub.status.idle":"2023-12-27T04:27:04.649495Z","shell.execute_reply.started":"2023-12-27T04:27:02.472708Z","shell.execute_reply":"2023-12-27T04:27:04.648333Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:27:04.650603Z","iopub.execute_input":"2023-12-27T04:27:04.650866Z","iopub.status.idle":"2023-12-27T04:27:04.655836Z","shell.execute_reply.started":"2023-12-27T04:27:04.650844Z","shell.execute_reply":"2023-12-27T04:27:04.654735Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"<torch.utils.data.dataloader.DataLoader object at 0x7f537e48ed40>\n","output_type":"stream"}]},{"cell_type":"code","source":"model2 = RatingModel(18)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:27:04.657055Z","iopub.execute_input":"2023-12-27T04:27:04.657336Z","iopub.status.idle":"2023-12-27T04:27:04.804784Z","shell.execute_reply.started":"2023-12-27T04:27:04.657312Z","shell.execute_reply":"2023-12-27T04:27:04.803833Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# model = RatingModel()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:27:04.805891Z","iopub.execute_input":"2023-12-27T04:27:04.806344Z","iopub.status.idle":"2023-12-27T04:27:04.810974Z","shell.execute_reply.started":"2023-12-27T04:27:04.806309Z","shell.execute_reply":"2023-12-27T04:27:04.809981Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import optim\ncriterion = nn.CrossEntropyLoss()\n\nlearning_rate = 1e-3\noptimizer = optim.Adam(\n    filter(lambda p: p.requires_grad, model2.parameters()),\n    lr=learning_rate,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:27:04.812280Z","iopub.execute_input":"2023-12-27T04:27:04.813066Z","iopub.status.idle":"2023-12-27T04:27:04.824809Z","shell.execute_reply.started":"2023-12-27T04:27:04.813011Z","shell.execute_reply":"2023-12-27T04:27:04.824013Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nNUM_EP = 15\nmodel2.to(device)\nfor ep in range(NUM_EP):\n\n    print(\"=\"*50)\n    for idx, (title_tensor, genre_tensor,rating_tensor) in enumerate(train_dataloader):\n        title_tensor = title_tensor.to(device)\n        genre_tensor = genre_tensor.to(device)\n        rating_tensor = rating_tensor.to(device)\n        model2 = model2.to(device)\n        out = model2(rating_tensor)\n\n        loss = criterion(out, genre_tensor)\n\n\n        if idx % 50 == 0 and idx > 0:\n          print(\"loss: \", loss)\n        optimizer.zero_grad()\n        loss.backward()\n        \n        optimizer.step()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:27:04.825916Z","iopub.execute_input":"2023-12-27T04:27:04.828300Z","iopub.status.idle":"2023-12-27T04:27:53.903225Z","shell.execute_reply.started":"2023-12-27T04:27:04.828270Z","shell.execute_reply":"2023-12-27T04:27:53.902298Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"==================================================\nloss:  tensor(4.7256, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0435, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.8088, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.4660, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(3.1083, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(3.6979, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.6493, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(3.1003, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.6697, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.7753, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.1545, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.7094, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.8118, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.9407, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(2.7925, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.2790, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.3064, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.9722, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.3146, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.4340, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.4050, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(2.4997, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.2738, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.3400, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.5701, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.1174, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(3.4375, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.5629, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(2.4061, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.4231, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.2621, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.2870, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.8727, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.1120, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1406, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(2.2625, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.1493, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0694, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1699, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.5939, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.0200, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1873, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(2.3479, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.0853, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.2570, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0887, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.4239, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.0025, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1619, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(2.1294, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.0923, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.9375, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0934, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.3075, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.3092, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0457, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(2.2859, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.0544, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.8694, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1670, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.2656, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.0651, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1329, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(2.0705, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.0321, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.8914, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0668, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.3027, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.0656, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1991, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(2.2954, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.0324, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.2520, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0397, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.6194, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.8748, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0724, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(2.0707, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.0238, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.8983, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1881, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.3456, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(2.1166, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0089, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(2.4722, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.0999, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.9246, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0220, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1551, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.7875, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1072, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(1.8283, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.0643, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0705, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0052, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.4002, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.8600, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1672, device='cuda:0', grad_fn=<DivBackward1>)\n==================================================\nloss:  tensor(1.8757, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.0400, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.9079, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(0.9945, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.0412, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.6664, device='cuda:0', grad_fn=<DivBackward1>)\nloss:  tensor(1.1805, device='cuda:0', grad_fn=<DivBackward1>)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q torchmetrics\nfrom torchmetrics.classification import MultilabelF1Score","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:27:53.904515Z","iopub.execute_input":"2023-12-27T04:27:53.904844Z","iopub.status.idle":"2023-12-27T04:28:13.079533Z","shell.execute_reply.started":"2023-12-27T04:27:53.904816Z","shell.execute_reply":"2023-12-27T04:28:13.078546Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"N, C = genre_tensor.shape\n\nauroc_all = 0\nf1_all = 0\nf1 = MultilabelF1Score(num_labels=C, threshold=0.5, average='macro').to(device)\nf1 = f1.to(device)\nfor title_tensor, genre_tensor,rating_tensor in test_dataloader:\n    rating_tensor = rating_tensor.to(device)\n    genre_tensor = genre_tensor.to(device)\n    model2 = model2.to(device)\n    out = model2(rating_tensor)\n    f1_batch = f1(out, genre_tensor)\n    f1_all += f1_batch\n\nprint('F1: ', f1_all/len(test_dataloader))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:28:13.080844Z","iopub.execute_input":"2023-12-27T04:28:13.081476Z","iopub.status.idle":"2023-12-27T04:28:14.331413Z","shell.execute_reply.started":"2023-12-27T04:28:13.081447Z","shell.execute_reply":"2023-12-27T04:28:14.330372Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"F1:  tensor(0.3284, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchmetrics.classification import MultilabelF1Score, MultilabelRecall, MultilabelPrecision\nN, C = genre_tensor.shape\n\nf1 = MultilabelF1Score(num_labels=C, threshold=0.5, average='macro')\nf1 = f1.to(device)\n\nrecall = MultilabelRecall(num_labels=C, threshold=0.5, average='macro')\nrecall = recall.to(device)\nprecision = MultilabelPrecision(num_labels=C, threshold=0.5, average='macro')\nprecision = precision.to(device)\n\nmodel2.eval()\n\nf1_all = 0\nrecall_all = 0\nprecision_all = 0\n\ntotal_acc_test = 0\ntotal_loss_test = 0\n\nwith torch.no_grad():\n  for title_tensor, genre_tensor,rating_tensor in test_dataloader:\n      #title_tensor = title_tensor.to(device)\n#       ids = title_tensor['ids'].to(device, dtype = torch.long)\n#       mask = title_tensor['mask'].to(device, dtype = torch.long)\n#       token_type_ids = title_tensor['token_type_ids'].to(device, dtype = torch.long)\n#       img_tensor = img_tensor.to(device)\n#       genre_tensor = genre_tensor.to(device)\n      #print(\"title_tensor\", title_tensor)\n    rating_tensor = rating_tensor.to(device)\n    genre_tensor = genre_tensor.to(device)\n    out = model2(rating_tensor)\n\n    #out = out.sigmoid()\n    out1 = (out > 0.5).float()\n\n    # f1_batch = f1(out, genre_tensor)\n    # f1_all += f1_batch\n    f1_val = f1(out, genre_tensor.type(torch.float))\n    f1_all += f1_val\n\n    recall_val = recall(out, genre_tensor.type(torch.int))\n    recall_all += recall_val\n    precision_val = precision(out, genre_tensor.type(torch.int))\n    precision_all += precision_val\n\n    acc = ((out > 0.5).int() == genre_tensor.type(torch.int)).float().mean().item()\n    total_acc_test += acc\n\ntest_acc = total_acc_test / len(test_dataloader)\n\nf1_all = f1_all / len(test_dataloader)\nrecall_all = recall_all / len(test_dataloader)\nprecision_all = precision_all / len(test_dataloader)\n\nprint(f'Test Accuracy: {test_acc:^10.4f}|Precision: {precision_all:^10.4f}|Recall: {recall_all}|F1-Score: {f1_all}')","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:28:14.332570Z","iopub.execute_input":"2023-12-27T04:28:14.332857Z","iopub.status.idle":"2023-12-27T04:28:15.180926Z","shell.execute_reply.started":"2023-12-27T04:28:14.332832Z","shell.execute_reply":"2023-12-27T04:28:15.179879Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Test Accuracy:   0.9354  |Precision:   0.2986  |Recall: 0.372833251953125|F1-Score: 0.321108877658844\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ","metadata":{}}]}