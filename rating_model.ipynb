{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-27T14:46:06.793612Z","iopub.status.busy":"2023-12-27T14:46:06.792625Z","iopub.status.idle":"2023-12-27T14:46:06.802346Z","shell.execute_reply":"2023-12-27T14:46:06.801212Z","shell.execute_reply.started":"2023-12-27T14:46:06.793574Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/mldog1/users.dat\n","/kaggle/input/mldog1/ratings.dat\n","/kaggle/input/mldog1/movies_train.dat\n","/kaggle/input/mldog1/genres.txt\n","/kaggle/input/mldog1/movies_test.dat\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:06.804419Z","iopub.status.busy":"2023-12-27T14:46:06.804099Z","iopub.status.idle":"2023-12-27T14:46:07.753618Z","shell.execute_reply":"2023-12-27T14:46:07.752500Z","shell.execute_reply.started":"2023-12-27T14:46:06.804391Z"},"trusted":true},"outputs":[],"source":["%ls"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:07.755699Z","iopub.status.busy":"2023-12-27T14:46:07.755260Z","iopub.status.idle":"2023-12-27T14:46:07.761717Z","shell.execute_reply":"2023-12-27T14:46:07.760879Z","shell.execute_reply.started":"2023-12-27T14:46:07.755658Z"},"trusted":true},"outputs":[],"source":["import pandas\n","import pandas as pd\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","import cv2\n","import os\n","from nltk import wordpunct_tokenize\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:07.764547Z","iopub.status.busy":"2023-12-27T14:46:07.764225Z","iopub.status.idle":"2023-12-27T14:46:15.428894Z","shell.execute_reply":"2023-12-27T14:46:15.428116Z","shell.execute_reply.started":"2023-12-27T14:46:07.764521Z"},"trusted":true},"outputs":[],"source":["users = pandas.read_csv('/kaggle/input/mldog1/users.dat', sep='::',\n","                        engine='python',\n","                        names=['userid', 'gender', 'age', 'occupation', 'zip']).set_index('userid')\n","ratings = pandas.read_csv('/kaggle/input/mldog1/ratings.dat', engine='python',\n","                          sep='::', names=['userid', 'movieid', 'rating', 'timestamp'])\n","movies_train = pandas.read_csv('/kaggle/input/mldog1/movies_train.dat', engine='python',\n","                         sep='::', names=['movieid', 'title', 'genre'], encoding='latin-1', index_col=False)\n","movies_test = pandas.read_csv('/kaggle/input/mldog1/movies_test.dat', engine='python',\n","                         sep='::', names=['movieid', 'title', 'genre'], encoding='latin-1', index_col=False)\n","movies_train['genre'] = movies_train.genre.str.split('|')\n","movies_test['genre'] = movies_test.genre.str.split('|')\n","\n","users.age = users.age.astype('category')\n","users.gender = users.gender.astype('category')\n","users.occupation = users.occupation.astype('category')\n","ratings.movieid = ratings.movieid.astype('category')\n","ratings.userid = ratings.userid.astype('category')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:15.430358Z","iopub.status.busy":"2023-12-27T14:46:15.430002Z","iopub.status.idle":"2023-12-27T14:46:19.363895Z","shell.execute_reply":"2023-12-27T14:46:19.362867Z","shell.execute_reply.started":"2023-12-27T14:46:15.430302Z"},"trusted":true},"outputs":[],"source":["unique_movie_ids = ratings['movieid'].unique()\n","ratings_dict = {}\n","\n","for i in unique_movie_ids:\n","    rate = np.zeros(6040) \n","    movie_ratings = ratings.loc[ratings['movieid']== i ] \n","    user_list = movie_ratings['userid'].tolist()\n","    rate_list = movie_ratings['rating'].tolist()\n","    for j in range(len(user_list)):\n","        rate[user_list[j]-1] = rate_list[j]\n","    ratings_dict[i] = rate"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:19.365525Z","iopub.status.busy":"2023-12-27T14:46:19.365183Z","iopub.status.idle":"2023-12-27T14:46:19.372523Z","shell.execute_reply":"2023-12-27T14:46:19.371478Z","shell.execute_reply.started":"2023-12-27T14:46:19.365495Z"},"trusted":true},"outputs":[],"source":["def tokenize(text):\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    text = text.lower()\n","    tokens = wordpunct_tokenize(text)\n","    tokens = tokens[:-1] # remove last token because it is the year which maybe is not useful\n","    return tokens\n","\n","def create_vocab():\n","    df = movies_train.copy()\n","    arr_title = df['title'].tolist()\n","    vocab = set()\n","    for title in arr_title:\n","        tokens = tokenize(title)\n","        vocab.update(tokens)\n","    vocab = list(vocab)\n","    pad_token = '<PAD>'\n","    unk_token = '<UNK>'\n","    vocab.append(pad_token)\n","    vocab.append(unk_token)\n","    return vocab"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:19.374008Z","iopub.status.busy":"2023-12-27T14:46:19.373746Z","iopub.status.idle":"2023-12-27T14:46:19.387096Z","shell.execute_reply":"2023-12-27T14:46:19.386376Z","shell.execute_reply.started":"2023-12-27T14:46:19.373982Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:19.388753Z","iopub.status.busy":"2023-12-27T14:46:19.388378Z","iopub.status.idle":"2023-12-27T14:46:19.404355Z","shell.execute_reply":"2023-12-27T14:46:19.403350Z","shell.execute_reply.started":"2023-12-27T14:46:19.388720Z"},"trusted":true},"outputs":[],"source":["class MLDataset(Dataset):\n","    def __init__(self, is_train=True):\n","        if is_train:\n","            self.data =  movies_train\n","        else:\n","            self.data = movies_test\n","        self.data['title_tokens'] = [tokenize(x) for x in self.data.title]\n","        self.ratings = ratings_dict\n","        # create vocab\n","        vocab = create_vocab()\n","        pad_token = '<PAD>'\n","        unk_token = '<UNK>'\n","        self.token2idx = {token: idx for idx, token in enumerate(vocab)}\n","\n","        # Create a binary vector for each word in each sentence\n","        MAX_LENGTH = 7\n","        vectors = []\n","        for title_tokens in self.data.title_tokens.tolist():\n","            if len(title_tokens) < MAX_LENGTH:\n","                num_pad = MAX_LENGTH - len(title_tokens)\n","                for idx in range(num_pad):\n","                    title_tokens.append(pad_token)\n","            else:\n","                title_tokens = title_tokens[:MAX_LENGTH]\n","            title_vectors = []\n","            for word in title_tokens:\n","                binary_vector = np.zeros(len(vocab))\n","                if word in vocab:\n","                    binary_vector[self.token2idx[word]] = 1\n","                else:\n","                    binary_vector[self.token2idx[unk_token]] = 1\n","                title_vectors.append(binary_vector)\n","\n","            vectors.append(np.array(title_vectors))\n","        self.data['vectors'] = vectors\n","\n","        # label genre\n","        with open('/kaggle/input/mldog1/genres.txt', 'r') as f:\n","            genre_all = f.readlines()\n","            genre_all = [x.replace('\\n','') for x in genre_all]\n","        self.genre2idx = {genre:idx for idx, genre in enumerate(genre_all)}\n","\n","    def __getitem__(self, index):\n","        title = self.data.iloc[index].title\n","#         img_path = self.data.iloc[index].img_path\n","        genre = self.data.iloc[index].genre\n","        movie_id = self.data.iloc[index].movieid\n","        try:\n","            ratings = self.ratings[movie_id]\n","            ratings = ratings/5\n","        except:\n","            #ratings = np.random.randint(5, size=(6040)) \n","            #ratings = ratings/5\n","            ratings = np.zeros([6040])\n","        rating_tensor = torch.from_numpy(ratings).float()\n","        # preprocess text\n","        title_vector = self.data.iloc[index].vectors\n","        title_tensor = torch.from_numpy(title_vector).float()\n","\n","        # preprocess im\n","\n","        # preprocess label\n","        genre_vector = np.zeros(len(self.genre2idx))\n","\n","        for g in genre:\n","            genre_vector[self.genre2idx[g]] = 1\n","        genre_tensor = torch.from_numpy(genre_vector).float()\n","        return title_tensor, genre_tensor, rating_tensor\n","\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:19.405661Z","iopub.status.busy":"2023-12-27T14:46:19.405411Z","iopub.status.idle":"2023-12-27T14:46:19.418901Z","shell.execute_reply":"2023-12-27T14:46:19.418145Z","shell.execute_reply.started":"2023-12-27T14:46:19.405637Z"},"trusted":true},"outputs":[],"source":["class RatingModel(nn.Module):\n","    def __init__(self, num_classes):\n","        super(RatingModel, self).__init__()\n","        self.dropout = nn.Dropout(0.2)\n","\n","        self.fc1 = nn.Linear(6040, 1024)\n","        self.bn1 = nn.BatchNorm1d(1024)\n","        self.relu1 = nn.ReLU()\n","\n","        self.fc2 = nn.Linear(1024, 512)\n","        self.bn2 = nn.BatchNorm1d(512)\n","        self.relu2 = nn.ReLU()\n","\n","        self.fc3 = nn.Linear(512, 256)\n","        self.bn3 = nn.BatchNorm1d(256)\n","        self.relu3 = nn.ReLU()\n","\n","        self.fc4 = nn.Linear(256, num_classes)\n","        \n","        \n","    def forward(self, x):\n","        x = self.bn1(self.relu1(self.fc1(x)))\n","        x = self.dropout(x)\n","        x = self.bn2(self.relu2(self.fc2(x)))\n","        x = self.dropout(x)\n","        x = self.relu3(self.fc3(x))\n","\n","        x = self.fc4(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:19.421998Z","iopub.status.busy":"2023-12-27T14:46:19.421729Z","iopub.status.idle":"2023-12-27T14:46:21.387400Z","shell.execute_reply":"2023-12-27T14:46:21.386398Z","shell.execute_reply.started":"2023-12-27T14:46:19.421974Z"},"trusted":true},"outputs":[],"source":["train_set = MLDataset(is_train=True)\n","test_set = MLDataset(is_train=False)\n","\n","BATCH_SIZE = 64\n","train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE,drop_last=True)\n","test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE,drop_last=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:21.389035Z","iopub.status.busy":"2023-12-27T14:46:21.388675Z","iopub.status.idle":"2023-12-27T14:46:21.523018Z","shell.execute_reply":"2023-12-27T14:46:21.522034Z","shell.execute_reply.started":"2023-12-27T14:46:21.389000Z"},"trusted":true},"outputs":[],"source":["model = RatingModel(18)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:21.524408Z","iopub.status.busy":"2023-12-27T14:46:21.524111Z","iopub.status.idle":"2023-12-27T14:46:21.528559Z","shell.execute_reply":"2023-12-27T14:46:21.527670Z","shell.execute_reply.started":"2023-12-27T14:46:21.524382Z"},"trusted":true},"outputs":[],"source":["# model = RatingModel()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:21.530091Z","iopub.status.busy":"2023-12-27T14:46:21.529818Z","iopub.status.idle":"2023-12-27T14:46:21.540363Z","shell.execute_reply":"2023-12-27T14:46:21.539586Z","shell.execute_reply.started":"2023-12-27T14:46:21.530056Z"},"trusted":true},"outputs":[],"source":["from torch import optim\n","criterion = nn.CrossEntropyLoss()\n","\n","learning_rate = 1e-3\n","optimizer = optim.Adam(\n","    filter(lambda p: p.requires_grad, model.parameters()),\n","    lr=learning_rate,\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-27T14:46:21.541869Z","iopub.status.busy":"2023-12-27T14:46:21.541509Z","iopub.status.idle":"2023-12-27T14:46:37.236908Z","shell.execute_reply":"2023-12-27T14:46:37.235558Z","shell.execute_reply.started":"2023-12-27T14:46:21.541832Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================================\n","==================================================\n","==================================================\n","==================================================\n","==================================================\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EP):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (title_tensor, genre_tensor,rating_tensor) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m      8\u001b[0m         title_tensor \u001b[38;5;241m=\u001b[39m title_tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m         genre_tensor \u001b[38;5;241m=\u001b[39m genre_tensor\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[15], line 57\u001b[0m, in \u001b[0;36mMLDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     55\u001b[0m rating_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(ratings)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# preprocess text\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m title_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvectors\n\u001b[1;32m     58\u001b[0m title_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(title_vector)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# preprocess im\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# preprocess label\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1716\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3789\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3787\u001b[0m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[1;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3789\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[1;32m   3792\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/managers.py:980\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    975\u001b[0m     result \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(result)\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# Such assignment may incorrectly coerce NaT to None\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, rl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    981\u001b[0m         result[rl] \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39miget((i, loc))\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","NUM_EP = 70\n","model.to(device)\n","for ep in range(NUM_EP):\n","\n","    print(\"=\"*50)\n","    for idx, (title_tensor, genre_tensor,rating_tensor) in enumerate(train_dataloader):\n","        title_tensor = title_tensor.to(device)\n","        genre_tensor = genre_tensor.to(device)\n","        rating_tensor = rating_tensor.to(device)\n","        model = model.to(device)\n","        out = model(rating_tensor)\n","        loss = criterion(out, genre_tensor)\n","\n","\n","        if idx % 50 == 0 and idx > 0:\n","          print(\"loss: \", loss)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        \n","        optimizer.step()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-12-27T14:46:37.237767Z","iopub.status.idle":"2023-12-27T14:46:37.238136Z","shell.execute_reply":"2023-12-27T14:46:37.237977Z","shell.execute_reply.started":"2023-12-27T14:46:37.237960Z"},"trusted":true},"outputs":[],"source":["!pip install -q torchmetrics\n","from torchmetrics.classification import MultilabelF1Score"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-12-27T14:46:37.239199Z","iopub.status.idle":"2023-12-27T14:46:37.239555Z","shell.execute_reply":"2023-12-27T14:46:37.239404Z","shell.execute_reply.started":"2023-12-27T14:46:37.239387Z"},"trusted":true},"outputs":[],"source":["from torchmetrics.classification import MultilabelF1Score, MultilabelRecall, MultilabelPrecision\n","N, C = genre_tensor.shape\n","\n","f1 = MultilabelF1Score(num_labels=C, threshold=0.7, average='macro')\n","f1 = f1.to(device)\n","\n","recall = MultilabelRecall(num_labels=C, threshold=0.7, average='macro')\n","recall = recall.to(device)\n","precision = MultilabelPrecision(num_labels=C, threshold=0.7, average='macro')\n","precision = precision.to(device)\n","\n","model.eval()\n","\n","f1_all = 0\n","recall_all = 0\n","precision_all = 0\n","\n","total_acc_test = 0\n","total_loss_test = 0\n","\n","with torch.no_grad():\n","    for title_tensor, genre_tensor,rating_tensor in test_dataloader:\n","    #title_tensor = title_tensor.to(device)\n","    #       ids = title_tensor['ids'].to(device, dtype = torch.long)\n","    #       mask = title_tensor['mask'].to(device, dtype = torch.long)\n","    #       token_type_ids = title_tensor['token_type_ids'].to(device, dtype = torch.long)\n","    #       img_tensor = img_tensor.to(device)\n","    #       genre_tensor = genre_tensor.to(device)\n","    #print(\"title_tensor\", title_tensor)\n","        rating_tensor = rating_tensor.to(device)\n","        genre_tensor = genre_tensor.to(device)\n","        out = model(rating_tensor)\n","\n","        #out = out.sigmoid()\n","        out1 = (out > 0.7).float()\n","\n","        # f1_batch = f1(out, genre_tensor)\n","        # f1_all += f1_batch\n","        f1_val = f1(out, genre_tensor.type(torch.float))\n","        f1_all += f1_val\n","\n","        recall_val = recall(out, genre_tensor.type(torch.int))\n","        recall_all += recall_val\n","        precision_val = precision(out, genre_tensor.type(torch.int))\n","        precision_all += precision_val\n","\n","        acc = ((out > 0.7).int() == genre_tensor.type(torch.int)).float().mean().item()\n","        total_acc_test += acc\n","\n","test_acc = total_acc_test / len(test_dataloader)\n","\n","f1_all = f1_all / len(test_dataloader)\n","recall_all = recall_all / len(test_dataloader)\n","precision_all = precision_all / len(test_dataloader)\n","\n","print(f'Test Accuracy: {test_acc:^10.4f}|Precision: {precision_all:^10.4f}|Recall: {recall_all}|F1-Score: {f1_all}')"]},{"cell_type":"markdown","metadata":{},"source":["## "]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4224362,"sourceId":7284990,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
